{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI的初步了解\n",
    "\n",
    "这节只解决下面几个问题：\n",
    "1. 如何理解AI？\n",
    "2. 用什么方法实现一个AI？\n",
    "3. 实现AI的具体过程是什么？\n",
    "4. 一些问题的回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何理解AI？\n",
    "\n",
    "AI的中文翻译是人工智能，意思就是通过计算机模拟人的智慧。所以，我们要意识到AI其实就是一种程序，只不过这个程序十分厉害。它不像传统的程序一样只能处理固定的，答案唯一的，确定的事情，AI可以像人一样处理很多模糊的事情。\n",
    "\n",
    "但再怎么厉害的AI他也是人设计出来的，所以它一定有某种设计思路。\n",
    "\n",
    "为了便于理解，我以一个翻译AI举例。我们的目的是实现一个可以将中文翻译成英文的AI。它不像传统的机器翻译，只是简单的根据单词和对应的中文含义强行拼合。我想要的是一个能够理解这个中文，然后根据中文的含义，得到对应的英文的这么一个AI。\n",
    "\n",
    "我刚才说了，AI本质依旧是一个程序，那么它自然是有输入输出的。如果是一个中译英的AI，那么它的输入就是一句中文，输出就是对应的一句英文。\n",
    "\n",
    "假设，我们把任意一句中文看做元素x，所有的中文句子可以构成一个集合X；任意一句英文看做元素y，所有的英文句子可以构成一个集合Y。那么，我们想要得到的理想的AI就是，在集合X中任意给一个元素x，可以在集合Y中找到对应的元素y。\n",
    "\n",
    "说到这里，大家应该已经能想到AI是什么了。高中数学，如果给定集合A中任意一个元素a，根据某种对应法则f可以在集合B中找到唯一确定的元素b，那么我们就说这种对应法则f就是A到B的一个函数。\n",
    "\n",
    "没错，AI其实就是一个函数。\n",
    "\n",
    "所以，如果我们想要设计实现一个AI，其实就是去寻找对应函数的这么一个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用什么方法实现一个AI？\n",
    "\n",
    "刚刚讲了，AI其实就是一个函数。但知道这个概念目前看来对我们设计实现一个AI没有什么帮助。所以，我们要继续深入理解一下AI。\n",
    "\n",
    "先想想我们目前知道什么？我们的目的是什么？如果什么都不知道那不可能实现AI，毕竟巧妇难为无米之炊。而不清楚自己的目的问题就更大了，甚至可能南辕北辙。这里还是以中译英为例。\n",
    "\n",
    "我们目前知道的是一些中文对应的英文翻译。比如我知道**你好**对应**hello**,**男人**对应**man**，**没有什么是容易的**对应**Nothing is easy**，**我是钢铁侠**对应**i'm iron man**，**我会给他一个他无法拒绝的提议**对应**I'm going to make him an offer he can't refuse**等等，我们可以知道非常多类似的数据。\n",
    "\n",
    "我们的目的呢，是给出任意一句中文，AI都能给出对应的英文翻译。\n",
    "\n",
    "注意，刚才说的我们能知道很多很多中英对应的数据，但不可能包含所有的中文句子。我们的目标是任意，任意一句中文，AI都能给出英文翻译，重点在任意上。也就是说，哪怕这个中文句子不在我们一开始知道的数据里，AI也能给出对应的英文翻译。\n",
    "\n",
    "现在我们梳理了我们当前的已知和目标，怎么实现这个AI呢？还记得刚才说过的，AI就是一个函数。所以，我们先把刚才的问题转换为数学问题再看一看。\n",
    "\n",
    "我们把刚才的中文看做x，英文看做y。比如**你好**就是x1，**hello**就是y1。那么现在的数据就是知道了x1，y1，x2，y2等等一连串的数据。而相应的中译英AI自然就是函数f(x)，它要满足的就是输入x1得到y1，输入x2得到y2。\n",
    "\n",
    "看到这里，一些同学估计又理解了。把(x,y)看做一个点这不就是曲线拟合嘛。根据已知的数据点(x,y)，找到最符合数据点的函数f(x)。\n",
    "\n",
    "所以，我们完全可以用解决拟合的办法来实现AI。实现曲线拟合的方法特别多，但同时能用来实现AI的就一个-梯度下降法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现AI的具体过程是什么？\n",
    "\n",
    "梯度下降法，顾名思义这个方法和梯度有关。而梯度呢，大家把他理解为导数就可以了。说的再多也不如动手做一下，所以，我们用梯度下降法手动实现一个曲线拟合。\n",
    "\n",
    "首先，我们先准备100个数据，这里就是x和y。注意x和y都是准确值。理论上这些数据是我们采集到的，而不是我们自己生成的。但这里就假装是我们采集到的吧。准备好了那我们就开始了。\n",
    "\n",
    "第一步：假设函数形式。我们先猜个f(x)，比如我这里猜测这个函数可能是一个4次多项式。那么`f(x)=w0*x**4+w1*x**3+w2*x**2+w3*x+w4`，w1到w5是系数，我们就先都给成1。这样我们就得到了一个完整的f(x)。其中我们将x输入f(x)得到的值记为y',比如输入xi得到是yi'。很自然，一开始yi'和yi差的很多，因为这个f(x)并不是我们想要的f(x)，不是正确的f(x)。那它为什么不是正确的f(x)呢？有两个可能得原因，一呢，就是正确的函数并不是一个四次多项式，可能是五次，六次，甚至更高次。二呢，就是系数w不正确，w1到w5的值不对。如果值正确，那么f(x)就会是正确的，我们想要的那个函数。\n",
    "\n",
    "第一种原因我们先不讨论，这里我们就认为f(x)是一个四次多项式是正确的。我们来讨论第二种原因。如果是因为系数w不正确，那么什么是正确的w呢？我们怎么判断这个系数w是正确的？很简单，只要每一个y'都十分接近y，那我们就认为w是正确的。那怎么判断y'和y的接近程度或者误差大小呢？那就需要进行第二步了。\n",
    "\n",
    "第二步：我们依照公式计算y'和y的误差，公式是J=E(yi'-yi)^2。首先来看下(yi'-yi)^2,这是yi'和yi距离的平方。求和之后呢，就是所有距离的平方和。如果y'和y差的有点远，那么(y'-y)^2就会大，相反，它就会小。而且，它是一个整体判断。如果只是一些点接近另一些点远离，那整个J依旧会很大。如果计算的J很小，那说明每个点y'都十分靠近y。很明显，J也是一个函数，我们把它叫做损失函数。通过这个函数J，我们就能判断y'和y的接近程度。\n",
    "\n",
    "有了J之后做什么呢？记住，我们得到J是为了判断w是不是正确的。假设计算的损失函数J很大，那就意味着w不正确，接下来该做什么呢？接下来就需要执行第三步。\n",
    "\n",
    "第三步：我们计算损失函数在每个w处的导数del_w。注意，这里是w，不是x。刚才说J是一个函数，但没说它是x的函数。我们仔细研究下J。`J=E(yi'-yi)^2=E(f(xi)-yi)^2=E(w0*xi**4+w1*xi**3+w2*xi**2+w3*xi+w4 - yi)`。注意，每次计算J的时候xi和yi都是固定不变的数据，所以，影响J的数是w，所以J是关于w的函数。\n",
    "\n",
    "有人可能会蒙。w不是也是固定的值吗？刚才不都给的1，怎么他就是自变量了？\n",
    "\n",
    "注意，我们假设f(x)是一个四次函数，我们求的是f(x)，而决定f(x)的是系数w而不是x，我们正是通过改变w来得到一个正确的f(x),所以w不是一个固定的值。给了1只是暂时取值为1，不代表它就不能改变了。因此，决定J的同样是w不是x，所以w才是自变量。\n",
    "\n",
    "举个例子，有四个f(x),第一个w都是1，第二个都是2，第三个都是3，第四个都是4。然后计算J，这时你会发现，带入的x都是固定的，不同的J只是因为w不同。所以w才是自变量。\n",
    "\n",
    "说了这么多，还记得第三步做了什么吗？计算了J关于w的导数，每个w处的导数都算。如果不会计算导数，这里可以先放着。你就知道能计算就可以了。为什么要计算导数？为了更改系数w。所以接下来要执行第四步。\n",
    "\n",
    "第四步：更改系数w，公式为w_new = w_old - alpha*del_w。这里的w_old是原来的w，alpha是一个我们自己设置的值，一般比较小。del_w就是计算的导数了。w_new就是新得到的w。根据这个公式得到的w会比原本的w更好，也就是说损失函数J更小。 接着来解释下为什么这个公式能用来更改w。\n",
    "\n",
    "首先我们先得理解梯度，这个方法叫做梯度下降法足以说明梯度的重要性。梯度，其实是一个矢量，它有大小，有方向。大小不用说，重点是方向。梯度的方向是函数增大的方向。\n",
    "\n",
    "我用导数举个例子，导数是最简单的梯度，所以梯度具有的性质导数也具有。假设h(x)=x^2。当x=1时，h(1)=1,h'(1)=2。有人可能会说，这个导数是2，你刚才说梯度有大小有方向，导数是最简单的梯度，这个2的大小我理解，但方向是哪来的？\n",
    "\n",
    "这不仅是2，而且是+2，这个正号就是方向。它是说，从x=1这个点，沿着x轴正方向走函数h(x)的值一定变大。x=1是一个点，一个点加上一个矢量得到另一个点。比如1+0.1*2=1.2,这里0.1就是alpha，1.2就是另一个点。当x=1.2时，y=1.44。是不是变大了。这就是刚才说的梯度的方向是函数增大的方向的含义。\n",
    "\n",
    "我们的目的是希望J变小，而不是变大，所以公式w_new = w_old - alpha*del_w这里用的是减法，而不是加法。还是刚才的例子，1-0.1x2=0.8,此时y=0.64是不是变小了。alpha是用来控制每次改变的幅度的。为什么要控制幅度呢？还是刚才那个例子，假设不控制幅度，alpha等于1，那么1-1x2=-1，此时y=1,没变化。甚至如果alpha是2的话，1-2x2=-3，此时y=9,甚至变大了，所以alpha要小。\n",
    "\n",
    "好了，我们现在得到了更新w的方法。接下来呢？解下来就是从第二步开始循环重复，因为一次更新不会得到理想的w，需要多次更新慢慢逼近理想的w。重复到什么程度就算合适呢？自己判断呗，比如我觉得重复个100次就合适，此时J足够小了，如果不合适我再循环重复。\n",
    "\n",
    "这就是完整的曲线拟合过程。下面就是代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "w_real = np.array([4,-5,-0.7,-0.02,-10.13])\n",
    "def real_xy():\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = w_real[0] * x **4+w_real[1] * x ** 3 +w_real[2] * x ** 2 +w_real[3] * x +w_real[4]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "w = np.array([1, 1, 1, 1, 1],dtype=np.float32)\n",
    "\n",
    "\n",
    "def predict_f(x):\n",
    "    global w\n",
    "    return w[0] * x**4 + w[1] * x**3 + w[2] * x**2 + w[3] * x + w[4]\n",
    "\n",
    "\n",
    "def loss(y_pre, y):\n",
    "    return np.sum((y_pre - y) ** 2)\n",
    "\n",
    "\n",
    "def gradient_w(x, y, y_pre):\n",
    "    global w\n",
    "    g_w = np.zeros_like(w)\n",
    "    m = len(w)\n",
    "    for i in range(m):\n",
    "        g_w[i] = 2 * np.sum((y_pre - y) * np.power(x, m - 1 - i))\n",
    "    return g_w\n",
    "\n",
    "# 得到准确的数据x,y\n",
    "x, y = real_xy()\n",
    "# 循环迭代次数\n",
    "epochs = 100\n",
    "# alpha值\n",
    "alpha = 0.0000001\n",
    "# 保存每次的系数w和损失函数J\n",
    "w_list = [w[:]]\n",
    "J_list = []\n",
    "for epoch in range(epochs):\n",
    "    # 1.计算预测y'\n",
    "    y_pre = predict_f(x)\n",
    "    # 2.计算损失函数J\n",
    "    J = loss(y_pre, y)\n",
    "    # 3.计算梯度\n",
    "    g_w = gradient_w(x, y, y_pre)\n",
    "    # 4.更新w\n",
    "    w = w - alpha * g_w\n",
    "    # 保存w和J,便于分析\n",
    "    w_list.append(w[:])\n",
    "    J_list.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看损失函数J的变化\n",
    "plt.plot(J_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看函数f随系数w的变化\n",
    "for w_i in w_list[0::20]:\n",
    "    w = w_i\n",
    "    y_pre = predict_f(x)\n",
    "    plt.cla()  # 清除旧图形\n",
    "    plt.plot(x, y,x, y_pre)\n",
    "    plt.draw()  # 重绘图形\n",
    "    plt.pause(0.1)  # 暂停一会儿，以便观察\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过实际动手，相信大家都对曲线拟合有了一些认识。其实AI的原理也是完全相同的。AI的计算过程和拟合曲线基本相同。\n",
    "\n",
    "第一步：收集数据。\n",
    "\n",
    "第二步：先设计一个原始AI模型出来，并对系数赋初值。就像我们一开始设计f(x)是一个四次多项式；\n",
    "\n",
    "第三步：计算损失函数J。不同的AI损失函数可能不同。\n",
    "\n",
    "第四步：计算梯度。AI的梯度和拟合曲线的梯度计算方法完全不同，但目标还是一样的，依旧是求取梯度。\n",
    "\n",
    "第五步：更新参数w。AI有了很多更好的更新公式，但基本原理都是相同的。\n",
    "\n",
    "第六步：重复三四五步，直到合适。\n",
    "\n",
    "从上面我们能知道所谓的AI其实也是由许许多多的公式构成的，这些公式也存在系数w，在AI里，系数w被称作权重或者参数。它是一个AI的核心。求取权重的方法是通过循环求取梯度来更新权重w。在AI中，这种循环更新w的过程称作训练或者学习。像循环次数epochs,alpah这种对结果影响很大但由我们自己取值的参数称作超参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些问题的回答\n",
    "\n",
    "1. 初始AI就像是四次多项式一样，就已经完全决定了AI的结构，对吗？\n",
    "\n",
    "是的，后面的学习训练都只是求权重的过程。我们所谓的chatgpt，LLama，SD等AI他们最大的区别就是模型不同，也就是初始AI的结构不同。如果只是权重不同，那其实算作同一个AI。比如Stable Diffusion有很多版本，这些版本最大的区别一个就是权重数量不同，另一个就是权重值不同，但任何版本其实都是同一种模型。\n",
    "\n",
    "2. 那AI模型怎么设计？\n",
    "\n",
    "学习前人验证过的模型，比如CNN，RNN，Gan，Transformer等等。然后自己再选择一个比较合适的再针对性进行更改。\n",
    "\n",
    "3. 如果我是想从头设计AI呢？设计一个和主流AI都不同的模型\n",
    "\n",
    "你该不会觉得我会吧？\n",
    "\n",
    "4. 如果学AI就是把别人设计好的模型拿过来训练学习一下，求个权重，那我们在学什么？\n",
    "\n",
    "首先是学不同模型的结构具体是什么，里面都是什么公式，数据是如何变化的？学了这些大家就会使用一个现成的AI了。\n",
    "\n",
    "其次是学每一个公式的目的是什么？它是为了解决什么问题提出的？学了这些，就可以比较针对性的分析AI模型遇到的问题了。\n",
    "\n",
    "然后是。。。然后我也不知道，目前我也只学到这里。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
